# ====================================
# Scraper configuration file
# ====================================
#
# each line must not contain spaces and must be in the form:
# PARAM_NAME=paramValue
#
# For all the parameters please visit:
# http://doc.scrapy.org/en/latest/topics/settings.html#topics-settings

# The maximum depth that will be allowed to crawl for any site. If 0, no limit will be imposed
DEPTH_LIMIT=2

# The maximum number of pages per site
MAX_NUM_PAGES_PER_SITE=5

# Solr parameters
SOLR_IP_ADDRESS=localhost
SOLR_PORT_NUMBER=8983
#SOLR_PORT_NUMBER=8080
SOLR_CORE_NAME=test

# Postgres parameters
POSTGRES_HOST=localhost
POSTGRES_PORT=5433
#POSTGRES_DATABASE=foia
POSTGRES_DATABASE=S3
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password

# The file that will be used to store scraped binary files
# use linux folder separator and avoid the last /
BIN_FOLDER=c:/rootjuice2/conf/bin

# The tika app jar that will be used to extract text from binary files
TIKA_APP_JAR=C:/rootjuice2/rootjuice2/tika-app-1.18.jar

# The folder that will contain generated logfiles
# use linux folder separator and avoid the last /
LOG_FILE_FOLDER=c:/rootjuice2/logs

# Set the log level
#LOG_LEVEL=CRITICAL
#LOG_LEVEL=ERROR
#LOG_LEVEL=WARNING
LOG_LEVEL=INFO
#LOG_LEVEL=DEBUG